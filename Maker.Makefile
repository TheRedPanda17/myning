# WARNING: DO NOT EDIT THIS FILE. Update it by running `make self-update`.
# If you'd like to make a change, please submit an MR: https://in.thewardro.be/youversion/api/maker

# TODO in the future when Macs ship with GNU Make 4 by default I'd like to use the snippet below.
# Then I could remove all the tabs from the file.
# ifeq ($(origin .RECIPEPREFIX), undefined)
#   $(error This Make does not support .RECIPEPREFIX. Please use GNU Make 4.0 or later)
# endif
# .RECIPEPREFIX = >

# Use bash not sh
SHELL := bash
# Ensures each Make recipe is ran as one single shell session, rather than one new shell per line.
.ONESHELL:
# Without this your build may keep executing even if there was a failure in one of the targets.
.SHELLFLAGS := -eu -o pipefail -c

# By default, Makefile targets are "file targets" - they are used to build files from other files.
# Make assumes its target is a file, and this makes writing Makefiles relatively easy.
# However, sometimes you want your Makefile to run commands that do not represent physical files in
# the file system. BUT if a file exists with that name Make will be confused. PHONY overrides
# Makes default usage of a file as the target.
#
# *BUT* it's breaking my wildcards so I have to declare an actual tests
.PHONY: githooks spec tests venv

# Can't use .DEFAULT - it breaks my parent catch-all at the bottom
# .DEFAULT: _help-default

# VARIABLES
GITLAB_TOKEN = ydRAF2sEfn6j8tUqR9Db

# Lists of pip tools in & out files
PIP_TOOLS_IN_FILES = $(wildcard requirements*.in)
PIP_TOOLS_OUT_FILES := $(wildcard requirements*.txt)

# I prefixed all these with underscores so they are hidden from BASH completion because I didn't
# like all the -defaults showing up

_help-default:
	@echo "make api-docs"
	@echo "    Generate api docs from swagger cli via generated json spec"
	@echo "make black"
	@echo "    Lint the project with the Black formatter"
	@echo "make build"
	@echo "    Build Python package for distribution"
	@echo "make ci-checkout-branch"
	@echo "    Checkout a branch in the active git environment via CI"
	@echo "make ci-request-merge"
	@echo "    Request to merge the active git branch via CI"
	@echo "make clean"
	@echo "    Remove all Python compile & cache files"
	@echo "make configs"
	@echo "    Setup default configs for a project (setup.cfg & pyproject.toml)"
	@echo "make couchbase"
	@echo "    Pulls down couchbase cache"
	@echo "make db-docs"
	@echo "    Generate database docs for the given database connection"
	@echo "make deps-add"
	@echo "    Add a new dependency to a project using pip-tools"
	@echo "make deps-install"
	@echo "    Install project dependencies using pip-tools"
	@echo "make deps-update"
	@echo "    Update project dependencies using pip-tools"
	@echo "make detect-secrets"
	@echo "    Run detect-secrets linter"
	@echo "make docker-clean"
	@echo "    Clean up unused docker images & restart Docker"
	@echo "make docker-down"
	@echo "    Close all docker containers for project"
	@echo "make docker-up"
	@echo "    Start up all docker containers for project"
	@echo "make flake8"
	@echo "    Run flake8 linter"
	@echo "make git-cleanup"
	@echo "    Cleans up all branches merged into main both locally & in remote origin and orphaned commits"
	@echo "make githooks"
	@echo "    Register git hooks dir"
	@echo "make gitignore"
	@echo "    Grab the latest Python default gitignore from Gitlab"
	@echo "make gitlab-service-token"
	@echo "    Get the service token from Kubernetes required for Gitlab deployments"
	@echo "make gitlab-version"
	@echo "    Use Gitlab's API to get the version number we are running"
	@echo "make git-submodules"
	@echo "    Initialize and setup git submodules for project"
	@echo "make isort"
	@echo "    Run isort linter"
	@echo "make k8s-cluster-info"
	@echo "    Get the Kubernetes Cluster Address & CA Certificate for your currently configured cluster in kubectx"
	@echo "make kubeval"
	@echo "    Run kubeval linter on kubernetes folder"
	@echo "make lint"
	@echo "    Run all linters"
	@echo "make postgres"
	@echo "    Migrate the latest Yoyo file on the current environment"
	@echo "make pull-crowdin"
	@echo "    Pull latest strings from Crowdin Bible API Project"
	@echo "make pylint"
	@echo "    Run pylint linter"
	@echo "make pycodestyle"
	@echo "    Run pycodestyle linter"
	@echo "make run"
	@echo "    Run your app locally"
	@echo "make self-update"
	@echo "    Update the parent Makefile"
	@echo "make sleep"
	@echo "    Sleep for a 10 seconds"
	@echo "make tests"
	@echo "    Run pytests"

# The *ONLY* reason this is here is for BASH completion
__hackerydonotuseorelse: api-docs black build ci-checkout-branch ci-request-merge clean configs db-docs deps-add deps-install deps-update detect-secrets docker docker-clean docker-up docker-down flake8 git-cleanup githooks gitignore gitlab-service-token gitlab-version git-submodules isort k8s-cluster-info kubeval lint postgres pull-crowdin pycodestyle pylint run self-update sleep tests

_api-doc%-default:
	@rm swagger_container.tmp || true;
	@docker run --cidfile swagger_container.tmp swaggerapi/swagger-codegen-cli-v3:latest version
	@yaml_folder=`python -c 'import site; print(site.getsitepackages()[0])'`/youversion/red/$${spec_package_name}/api; \
	 container_id=`cat swagger_container.tmp`; \
	 docker cp $${yaml_folder}/service.yaml $${container_id}:/root/service.yaml; \
	 docker commit $${container_id} swaggerapi/swagger-codegen-cli-v3:$${spec_package_name};
	@rm swagger_container.tmp
	@docker run --cidfile swagger_container.tmp swaggerapi/swagger-codegen-cli-v3:$${spec_package_name} generate -i /root/service.yaml -l openapi -o /root > /dev/null
	@container_id=`cat swagger_container.tmp`; \
	 docker cp $${container_id}:/root/openapi.json .
	@rm swagger_container.tmp

_black-default:
	@black --help > /dev/null || (echo "Error: black not found"; exit 1)
	@echo "> running black..."
	@black . --check
	@echo "black code format looks good!"

_build-default:
	@python setup.py sdist bdist_wheel

_ci-checkout-branch-default: _git_set_user _git_set_email _git_set_origin
	@echo "> Checkout out a new branch..."
ifdef BRANCH
	git checkout -B $(BRANCH)
else
	git checkout -B "$$(date +'%m-%d')-Maker"
endif

_ci-request-merge-default:
	@echo "> Attempting commit/push files..."
	@if [[ ! -z $${CI_PROJECT_URL} ]]; then \
		mkdir -p ~/.ssh; \
		chmod 700 ~/.ssh; \
		echo "$${REPO_HOST_KEY}" >> ~/.ssh/known_hosts; \
		sed -i -r -e '/SendEnv LANG LC*/d' /etc/ssh/ssh_config; \
		eval $$(ssh-agent -s); \
		echo "$${AUTO_UPGRADE_SSH_PRIVATE_KEY}" | base64 --decode | ssh-add -; \
	 fi; \
	 if [[ -z "$${files}" ]]; then \
	 	files = "*"; \
	 fi; \
	 git add -A $${files}; \
	 if [ `git status | grep "nothing to commit" | wc -l` -eq "1" ]; then \
		echo "No resulting changes were made"; \
		exit 0; \
	 fi; \
	 if [[ -z "$${message}" ]]; then \
	 	message = "CI Maker Update"; \
	 fi; \
	 git commit --message="$${message}"; \
	 git push -f -v origin `git rev-parse --abbrev-ref HEAD`; \
	 echo "> Attempting merge request..."; \
	 if [[ -z $${CI_PROJECT_URL} ]]; then \
		CI_PROJECT_URL=`git remote get-url origin`; \
	 fi; \
	 CI_PROJECT_URL=`echo $${CI_PROJECT_URL} | sed "s~\.git~~g"`; \
	 branch=`git rev-parse --abbrev-ref HEAD`; \
	 [[ $${CI_PROJECT_URL} =~ ^https?://[^/]+ ]] && gitlab_api="$${BASH_REMATCH[0]}/api/v4/"; \
	 if [[ -z $${CI_PROJECT_ID} ]]; then \
		[[ $${CI_PROJECT_URL} =~ ^https?://[^/]+ ]] && rel_proj_url=`echo $${CI_PROJECT_URL} | sed "s~$${BASH_REMATCH[0]}/~~g" | sed "s~/~%2F~g"`; \
		CI_PROJECT_ID=`curl --silent "$${gitlab_api}projects/$${rel_proj_url}" --header "PRIVATE-TOKEN:$${GITLAB_API_TOKEN}"`; \
		CI_PROJECT_ID=`echo $${CI_PROJECT_ID} | grep -Eo "\"?id\"?:[0-9]+," | grep -Eo "[0-9]+" | head -1`; \
	 fi; \
	 if [[ -z $${CI_PROJECT_ID} ]]; then \
		 exit 1; \
	 fi; \
	 target_branch=`curl --silent "$${gitlab_api}projects/$${CI_PROJECT_ID}" --header "PRIVATE-TOKEN:$${GITLAB_API_TOKEN}" | grep -Eo "\"default_branch\":\"\w+\"" | sed "s~\"~~g" | sed "s~default_branch:~~g"`; \
	 if [[ -z $${GITLAB_USER_ID} ]]; then \
		user_name=`git config user.name`; \
		GITLAB_USER_ID=`curl --silent "$${gitlab_api}users/$${user_name}" --header "PRIVATE-TOKEN:$${GITLAB_API_TOKEN}" | grep -Eo "\"?id\"?:[0-9]+," | grep -Eo "[0-9]+" | head -1`; \
	 fi; \
	 body="{\"id\": $${CI_PROJECT_ID}, \
		\"source_branch\": \"$${branch}\", \
		\"target_branch\": \"$${target_branch}\", \
		\"remove_source_branch\": true, \
		\"title\": \"CI Auto Update\", \
		\"assignee_id\":\"$${GITLAB_USER_ID}\"}"; \
	 list_mr=`curl --silent "$${gitlab_api}projects/$${CI_PROJECT_ID}/merge_requests?state=opened" --header "PRIVATE-TOKEN:$${GITLAB_API_TOKEN}"`; \
	 if [ `echo $${list_mr} | grep -o "\"source_branch\":\"$${branch}\"" | wc -l` -eq "0" ]; then \
		curl -X POST "$${gitlab_api}projects/$${CI_PROJECT_ID}/merge_requests" \
			--header "PRIVATE-TOKEN:$${GITLAB_API_TOKEN}" \
			--header "Content-Type: application/json" \
			--data "$${body}"; \
	 else \
		echo "No new merge request opened"; \
	 fi;

_clea%-default: # works as clear or clean
	@echo "> Cleaning python compile files..."
	@find . -name '*.pyc' -exec rm -f {} +
	@find . -name '*.pyo' -exec rm -f {} +
	@find . -name '__pycache__' -exec rm -Rf {} +
	@echo "All done!"

_config%-default:
	@jq --help > /dev/null || (echo "Error: Unable to download configs! Please install jq with `brew install jq`."; exit 1)
	@echo "> Downloading default configs..."
	@curl -s --request GET --header 'PRIVATE-TOKEN: $(GITLAB_TOKEN)' 'https://in.thewardro.be/api/v4/projects/718/repository/files/setup.cfg?ref=main' | jq -r '.content' | base64 --decode > setup.cfg
	@curl -s --request GET --header 'PRIVATE-TOKEN: $(GITLAB_TOKEN)' 'https://in.thewardro.be/api/v4/projects/718/repository/files/pyproject.toml?ref=main' | jq -r '.content' | base64 --decode > pyproject.toml
	@curl -s --request GET --header 'PRIVATE-TOKEN: $(GITLAB_TOKEN)' 'https://in.thewardro.be/api/v4/projects/718/repository/files/.pylintrc?ref=main' | jq -r '.content' | base64 --decode > .pylintrc
	@echo "Configs downloaded successfully!"

_couchbase-default:
	@curl http://$${host}:8091/pools/default -d memoryQuota=256 -d indexMemoryQuota=256 -d ftsMemoryQuota=256
	@curl http://$${host}:8091/node/controller/setupServices -d services=kv%2Cn1ql%2Cindex%2Cfts
	@curl http://$${host}:8091/settings/web -d port=8091 -d username=Administrator -d password=password
	@curl http://$${host}:8091/pools/default/buckets -u Administrator:password -d name=$${name} -d ramQuotaMB=256 -d authType=sasl -d saslPassword=password -d bucketType=memcached -d flushEnabled=1
	@sleep 10
	@echo ""
	@echo "Couchbase container is configured!"

_db-doc%-default:
	@if [[ -z $${dir} ]]; then \
		dir=$${PWD}/db_docs; \
	 fi; \
	 if [[ -z $${host} ]]; then \
		host=127.0.0.1; \
	 fi; \
	 if [[ -z $${port} ]]; then \
		port=5432; \
	 fi; \
	 if [[ -z $${name} ]]; then \
		name=youversiondev; \
	 fi; \
	 rm schema_container.tmp || true; \
	 if docker run --cidfile schema_container.tmp --network host schemaspy/schemaspy:latest -t pgsql -host $${host} -port $${port} -db $${name} -u dev; then \
		mkdir -p $${dir}; \
		rm -rf $${dir}/*; \
		container_id=`cat schema_container.tmp`; \
		docker cp $${container_id}:/output/. $${dir}; \
		docker stop $${container_id}; \
		docker rm $${container_id}; \
		rm schema_container.tmp; \
	 else \
	 	exit 1; \
	 fi;

# TODO add a pip install --upgrade pip to a specific version using a global var
_upstall-pip-tools:
	@echo "> Updating/installing pip-tools..."
	@pip install --upgrade pip-tools > /dev/null 2>&1

# Requirements file compilation *MUST* be done in this order for constraints to work properly
_compile_requirements:
	@echo "> Compiling requirements WITHOUT upgrading packages..."
	@if [ -f requirements.in ]; then pip-compile requirements.in --no-emit-trusted-host --no-emit-index-url; fi
	@if [ -f requirements-mikey.in ]; then pip-compile requirements-mikey.in --no-emit-trusted-host --no-emit-index-url; fi
	@if [ -f requirements-dev.in ]; then pip-compile requirements-dev.in --no-emit-trusted-host --no-emit-index-url; fi
	@if [ -f requirements-mikey-dev.in ]; then pip-compile requirements-mikey-dev.in --no-emit-trusted-host --no-emit-index-url; fi

_install_requirements:
	@echo "> Installing requirements..."
	@pip-sync $(PIP_TOOLS_OUT_FILES) > /dev/null
	@echo "> Dependencies successfully installed!"

_de%-add-default: _upstall-pip-tools _compile_requirements _install_requirements
	@echo "> Finished compiling requirements and adding new ones without checking for updated packages and installing them."

_de%-compile-default: _upstall-pip-tools _compile_requirements
	@echo "> Finished compiling requirements but did not install them."

_de%-install-default: _upstall-pip-tools _install_requirements
	@echo "> Finished install requirements but did not compile or check for updates."

_de%-update-default: _upstall-pip-tools
	@echo "> Compiling requirements AND upgrading packages..."
	@if [ -f requirements.in ]; then pip-compile requirements.in --upgrade --no-emit-trusted-host --no-emit-index-url; fi
	@if [ -f requirements-mikey.in ]; then pip-compile requirements-mikey.in --upgrade --no-emit-trusted-host --no-emit-index-url; fi
	@if [ -f requirements-dev.in ]; then pip-compile requirements-dev.in --upgrade --no-emit-trusted-host --no-emit-index-url; fi
	@if [ -f requirements-mikey-dev.in ]; then pip-compile requirements-mikey-dev.in --upgrade --no-emit-trusted-host --no-emit-index-url; fi
	@echo "> Installing requirements..."
	@pip-sync $(PIP_TOOLS_OUT_FILES) > /dev/null
	@echo "> Dependencies successfully updated!"

_detect-secrets-default:
	@detect-secrets --help > /dev/null || (echo "Error: detect-secrets not found"; exit 1)
	@echo "> Running detect-secrets..."
	@find . -path ./yoyo -prune -o -name '*.py' -exec detect-secrets-hook {} +
	@echo "No secrets found!"
	@echo

_docker-clean-default:
	@docker system prune --volumes
	@killall Docker
	@open /Applications/Docker.app

_docker-default: docker-up

_docker-down-default:
	@docker-compose down

_docker-up-default:
	@docker-compose pull
	@docker-compose up -d

_flake8-default:
	@flake8 --help > /dev/null || (echo "Error: flake8 not found"; exit 1)
	@echo "> running flake8..."
	@flake8
	@echo "flake8 looks good!"
	@echo

_git-cleanup-default:
	@echo "> Checking out main..."
	@git checkout main
	@echo "> Updating remotes..."
	@git remote update > /dev/null 2>&1
	@echo "> Stashing & pulling..."
	@CLEAN=`git status --porcelain`; \
	if [ ! -z "$$CLEAN" ]; then \
		git stash; \
	fi;
	@git pull origin main > /dev/null 2>&1
	@git stash pop | true > /dev/null 2>&1
	@echo "> Cleaning up local branches..."
	@if git branch --merged main | grep -v 'main'; then \
		read -p "> Delete local branches (y/n)? "; \
		if [ "$$REPLY" == "y" ]; then \
			git branch --merged main | grep -v 'main' | xargs git branch -d; \
		else \
			echo "> User aborted"; \
			exit 1; \
		fi; \
	else \
		echo "> No local branches to clean up!"; \
	fi;
	@if git branch -r --merged main | sed 's/ *origin\///' | grep -v 'main' > /dev/null 2>&1; then \
		echo "> The following remote branches are fully merged and will be removed:"; \
		git branch -r --merged main | sed 's/ *origin\///' | grep -v 'main'; \
		read -p "Continue (y/n)? "; \
		if [ "$$REPLY" == "y" ]; then \
			git branch -r --merged main | sed 's/ *origin\///' | grep -v 'main' | xargs -I% git push origin :% || true; \
		else \
			echo "> User aborted"; \
			exit 1; \
		fi; \
	else \
		echo "> No remote branches to clean up!"; \
	fi;
	@echo "> Checking for unreachable commits..."
	@git fsck --unreachable --no-progress
	@echo "> The above commits are unreachable and will be deleted if we continue with the cleanup"
	@read -p "Press any key to continue or Cntrl-C to bail out"
	@echo "> Pruning remotes..."
	@git prune
	@git remote prune origin > /dev/null 2>&1
	@git gc
	@echo "Git cleanup completed!"
	@echo 'T\_(-_-)_/T'

_githoo%-default: # ending s is optional
	@echo "> Creating githooks path in git config..."
	@git config core.hooksPath githooks
	@echo "Success"

_gitigno%-default:
	@jq --help > /dev/null || (echo "Error: Unable to download gitignore! Please install jq with `brew install jq`."; exit 1)
	@echo "> Downloading default gitignore..."
	@curl -s https://in.thewardro.be/api/v4/templates/gitignores/Python | jq -r '.content' > .gitignore
	@echo "# YouVersion custom added ignores." >> .gitignore
	@echo ".DS_Store" >> .gitignore
	@echo ".envrc" >> .gitignore
	@echo ".idea/" >> .gitignore
	@echo ".vscode/" >> .gitignore
	@echo ".pythonrc.py" >> .gitignore
	@echo "gcp-key.json" >> .gitignore
	@echo "Success"

gitlab-service-token:
	@kubectl -n kube-system describe secret $$(kubectl -n kube-system get secret | grep gitlab | awk '{print $$1}')

gitlab-version:
	@jq --help > /dev/null || (echo "Error: Unable to get gitlab-version! Please install jq with `brew install jq`."; exit 1)
	@curl -s --header "PRIVATE-TOKEN: BBSWYX26PhaBF8S65qWP" https://in.thewardro.be/api/v4/version | jq -r '.version'

_git_set_email:
ifdef GIT_EMAIL
	git config --global user.email "$(GIT_EMAIL)"
endif

_git_set_origin:
ifdef ORIGIN
	git remote set-url origin git@in.thewardro.be:$(ORIGIN).git
else ifdef CI_PROJECT_PATH
	git remote set-url origin git@in.thewardro.be:$(CI_PROJECT_PATH).git
endif

_git_set_user:
ifdef GIT_USER
	git config --global user.name "$(GIT_USER)"
endif

_git-submod%-default:
	@git submodule init
	@git submodule update

_isort-default:
	@isort --help > /dev/null || (echo "Error: isort not found"; exit 1)
	@if isort --version | grep "VERSION 4" 2> /dev/null; then \
		echo "> running isort v4..."; \
		isort -c; \
	else \
		echo "> running isort v5..."; \
		isort . --check --diff; \
	fi;
	@echo "isort looks good!"
	@echo

k8s-cluster-info:
	@echo "The cluster address is: "
	@kubectl cluster-info | grep 'Kubernetes master' | awk '/http/ {print $$NF}'
	@echo "The cluster ca cert is: "
	@kubectl get secret `kubectl get secrets | grep default-token- | awk '{print $$1}'` -o jsonpath="{['data']['ca\.crt']}" | base64 --decode
	@echo "The Gitlab token is: "
	@kubectl -n kube-system describe secret $$(kubectl -n kube-system get secret | grep gitlab | awk '{print $$1}') | grep 'token:'


_kubeval-default:
	@if hash kubeval 2>/dev/null; then \
		echo "> running kubeval..."; \
		find kubernetes -type f \( -name "*.yaml" ! -name "*eployment.yaml" \) -exec kubeval --ignore-missing-schemas {} +; \
		echo "kubeval looks good!"; \
	else \
		echo "No kubeval found, skipping."; \
	fi;

_lin%-default: pylint isort detect-secrets black kubeval
	@true # Targets with wildcards only work if you have something here, weird huh?

_postgres-default:
	@yoyo apply -c yoyo/$${api_env}.ini

_pull-crowdin-default:
	@if [ "$${export_crowdin}" != "skip" ]; then \
		curl https://api.crowdin.com/api/project/$${CROWDIN_PROJECT_ID}/export\?key\=$${CROWDIN_API_KEY}; \
	fi;
	@curl https://api.crowdin.com/api/project/$${CROWDIN_PROJECT_ID}/download/all.zip\?key\=$${CROWDIN_API_KEY} -o all.zip
	@rm -rf latest_strings/
	@mkdir -p latest_strings/
	@unzip all.zip -d latest_strings/
	@default_file="*"; \
	 file="$${file:-$${default_file}}"; \
	 ext="$${ext:-po}"; \
 	 out_dest="$${out_dest:-i18n}"; \
	 default_path_sed="s/$${file}.$${ext}/LC_MESSAGES\/$${file}.$${ext}/g"; \
	 path_sed="$${path_sed:-$${default_path_sed}}"; \
	 for iter_file in `find latest_strings -name "$${file}.$${ext}"`; do \
		 iter_path=`echo "$${iter_file}" | sed "s/latest_strings\///g"`; \
		 repo_path=`echo "$${iter_path}" | sed "s/-/_/g" | sed "$${path_sed}"`; \
		 repo_path="$${out_dest}/$${repo_path}"; \
		 mkdir -p `dirname $${repo_path}`; \
		 mv latest_strings/$${iter_path} $${repo_path}; \
		 if [[ -z `git ls-files $${repo_path}` ]]; then \
		 	git add $${repo_path}; \
		 elif [[ -z `git diff $${repo_path} | grep -E "^[+-]"` ]]; then \
			git checkout -- $${repo_path}; \
		 fi; \
	 done;
	@rm -rf latest_strings/;
	@rm all.zip;
	@if [ "$${export_mo}" != "skip" ]; then \
		for iter_file in $$(find i18n -name '*.po'); do \
			 file_diff=`git diff "$${iter_file}"`; \
			 mo_file=`echo $${iter_file%.po}.mo`; \
			 file_new_po_file=`git ls-files --other --exclude-standard "$${iter_file}"`; \
			 if [[ -z $${file_diff} || -z $${file_new_po_file} || ! -f $${mo_file} ]]; then \
				 pybabel compile -i $${iter_file} -o $${mo_file} || true; \
			 fi; \
		 done; \
	 fi;

_pycodestyle-default:
	@pycodestyle --help > /dev/null || (echo "Error: pycodestyle not found"; exit 1)
	@echo "> running pycodestyle..."
	@pycodestyle .
	@echo "pycodestyle looks good!"
	@echo

_pylint-default:
	@pylint --help > /dev/null || (echo "Error: pylint not found"; exit 1)
	@echo "> running pylint..."
	@find . -path ./tests/generated -prune -o -path ./tests/conftest.py -prune -o -path ./*/tests/generated -prune -o -path ./main.py -prune -o -path ./handlers/generated -prune -o -path ./handlers/__init__.py -prune -o -path ./*/views/generated -prune -o -path ./*/views/__init__.py -prune -o -path ./proto_transformers/generated -prune -o -path ./schemas/generated -prune -o -path ./*/schemas/generated -prune -o -path ./*/schemas/__init__.py -prune -o -path ./schemas/__init__.py -prune -o -path ./.eggs -prune -o -path ./yoyo -prune -o -path ./scripts -prune -o -path ./build -prune -o -name '*.py' -exec pylint --rcfile=.pylintrc {} +
	@echo "pylint looks good!"

_run-default:
	@python main.py

_self-up%-default: # works with update or upgrade
	@jq --help > /dev/null || (echo "Error: Unable to self-update! Please install jq with `brew install jq`."; exit 1)
	@echo "> Updating parent makefile..."
	@curl -s --request GET --header 'PRIVATE-TOKEN: $(GITLAB_TOKEN)' 'https://in.thewardro.be/api/v4/projects/718/repository/files/Makefile?ref=main' | jq -r '.content' | base64 --decode > Maker.Makefile
	@echo "Maker.Makefile updated successfully!"

_sleep-default:
	sleep 10

_tes%-default: # ending s is optional
ifneq (, $(shell pip freeze | grep yv-protest==2))
	@protest
else
	@pytest --help > /dev/null || (echo "Error: pytest not found"; exit 1)
	@echo "> Executing test suite..."
	@pytest tests/
endif


# Because of PHONY tests & githooks declarations, the default wildcard won't catch them so that's
# why these are here
# make test can be caught by the wildcard definition b/c theres no PHONY
githooks: _githooks-default
tests: _tests-default

# This is my hack to avoid the "Makefile: warning: overriding commands for target" output
%:  _%-default
	@true # Targets with wildcards only work if you have something here, weird huh?
